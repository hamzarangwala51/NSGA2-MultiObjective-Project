{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('colon.mat')\n",
    "dataset_name = \"colon,62\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc8c15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[1.07554696 1.15836249 1.25042    ... 1.14612804 1.28555731 1.57170883]\n",
      " [1.         1.         1.11394335 ... 1.         1.         1.41497335]\n",
      " [1.70757018 1.71600334 1.         ... 1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.11394335 ... 1.         1.         1.38021124]\n",
      " [1.         1.         1.         ... 1.         1.         1.39794001]\n",
      " [1.         1.         1.17609126 ... 1.         1.         1.32221929]]\n",
      "Y = [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "5966\n",
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Tue Mar 17 16:11:44 2015', '__version__': '1.0', '__globals__': [], 'X': array([[1.07554696, 1.15836249, 1.25042   , ..., 1.14612804, 1.28555731,\n",
      "        1.57170883],\n",
      "       [1.        , 1.        , 1.11394335, ..., 1.        , 1.        ,\n",
      "        1.41497335],\n",
      "       [1.70757018, 1.71600334, 1.        , ..., 1.        , 1.        ,\n",
      "        1.        ],\n",
      "       ...,\n",
      "       [1.        , 1.        , 1.11394335, ..., 1.        , 1.        ,\n",
      "        1.38021124],\n",
      "       [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
      "        1.39794001],\n",
      "       [1.        , 1.        , 1.17609126, ..., 1.        , 1.        ,\n",
      "        1.32221929]]), 'Y': array([[1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2]], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('Prostate.mat')\n",
    "dataset_name = \"Prostate,102\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36493e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('ALLAML.mat')\n",
    "dataset_name = \"ALLAML,72\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc84b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('lymphoma.mat')\n",
    "dataset_name = \"lymphoma,96\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd427a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('leukemia.mat')\n",
    "dataset_name = \"leukemia,72\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142aec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('GLI_85.mat')\n",
    "dataset_name = \"GLI,85\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('lung.mat')\n",
    "dataset_name = \"Lung,203\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b00530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('GLIOMA.mat')\n",
    "dataset_name = \"Glioma,50\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b053fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('CLL_SUB_111.mat')\n",
    "dataset_name = \"CLL_SUB_111,111\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "# Load the .mat file\n",
    "# (No. of features) : 12533\n",
    "mat_contents = scipy.io.loadmat('11Tumor_Split.mat')\n",
    "dataset_name = \"11Tumor,174\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X_train =data['datatrain']\n",
    "X_test = data['datatest']\n",
    "Y_test=data['labelstest'].ravel()\n",
    "Y_train = data['labelstrain'].ravel()\n",
    "print(Y_test.shape)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbacf746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "# Load the .mat file\n",
    "# (No. of features) : 2308\n",
    "mat_contents = scipy.io.loadmat('SRBCT_Split.mat')\n",
    "dataset_name = \"SRBCT_Split,83\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X_train =data['datatrain']\n",
    "X_test = data['datatest']\n",
    "Y_test=data['labelstest'].ravel()\n",
    "Y_train = data['labelstrain'].ravel()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "# Load the .mat file\n",
    "# (No. of features) : 9182\n",
    "mat_contents = scipy.io.loadmat('CARCINOM_Split.mat')\n",
    "dataset_name = \"CARCINOM,174\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X_train =data['datatrain']\n",
    "X_test = data['datatest']\n",
    "Y_test=data['labelstest'].ravel()\n",
    "Y_train = data['labelstrain'].ravel()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b607da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "# Load the .mat file\n",
    "# (No. of features) : 24481\n",
    "mat_contents = scipy.io.loadmat('Breast_Split.mat')\n",
    "dataset_name = \"Breast,97\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X_train =data['datatrain']\n",
    "X_test = data['datatest']\n",
    "Y_test=data['labelstest'].ravel()\n",
    "Y_train = data['labelstrain'].ravel()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "# Load the .mat file\n",
    "# (No. of features) : 7128\n",
    "mat_contents = scipy.io.loadmat('CNS_Split.mat')\n",
    "dataset_name = \"CNS,60\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X_train =data['datatrain']\n",
    "X_test = data['datatest']\n",
    "Y_test=data['labelstest'].ravel()\n",
    "Y_train = data['labelstrain'].ravel()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6361824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from pymoo.termination import get_termination\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
    "from pymoo.operators.crossover.ux import UniformCrossover\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
    "from sklearn.preprocessing import (StandardScaler, OrdinalEncoder,LabelEncoder, MinMaxScaler, OneHotEncoder)\n",
    "from pymoo.indicators.hv import HV\n",
    "import pandas as pd\n",
    "from pymoo.core.sampling import Sampling\n",
    "import random\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae551135",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data_test{dataset_name}.pkl', 'rb') as f:\n",
    "    data_test_open = pickle.load(f)\n",
    "X_test_op = data_test_open['X_test']\n",
    "Y_test_op = data_test_open['Y_test']\n",
    "\n",
    "avg_feat_testerror = []\n",
    "avg_testerror = []\n",
    "# Load the Pareto front binary vectors from files and perform voting\n",
    "feat_num = 7128\n",
    "save_dir = 'pareto_solutions'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "feature_frequency = np.zeros(feat_num, dtype=int)\n",
    "for avg_run in range(1,10+1):\n",
    "    for run in range(1, 10 + 1):\n",
    "        # Load the Pareto front binary vectors from the file\n",
    "        print('avgrun',avg_run)\n",
    "        print('run',run)\n",
    "        file_path = os.path.join(save_dir, f'pareto_front_solutions_run_{avg_run}_{run}_{dataset_name}.npy')\n",
    "        pareto_front_solutions = np.load(file_path)\n",
    "        print(pareto_front_solutions)\n",
    "        for vector in pareto_front_solutions:\n",
    "            feature_index = [i for i in range(len(vector)) if vector[i] == 1]\n",
    "            print(feature_index)\n",
    "            selected_features = feature_index\n",
    "            avg_feat_testerror.append(len(selected_features)) \n",
    "            avg_feat = np.mean(avg_feat_testerror)\n",
    "            print(avg_feat)\n",
    "            X_selected = X_train[:, selected_features]\n",
    "            testx = X_test_op[:,selected_features]\n",
    "            knn = KNeighborsClassifier(n_neighbors=5)\n",
    "            knn.fit(X_selected, Y_train)\n",
    "            ypred = knn.predict(testx)\n",
    "            ac = accuracy_score(Y_test_op, ypred)\n",
    "            err_test = 1-ac\n",
    "            print(ac)\n",
    "            print(err_test)\n",
    "            avg_testerror.append(err_test)\n",
    "            avg_error = np.mean(avg_testerror)\n",
    "            print('Avg error',avg_error)\n",
    "            # Create a dictionary where keys are column names and values are the variables\n",
    "            data = {\n",
    "                'Dataset': [dataset_name],\n",
    "                'Avg. of test error from 10 runs': [avg_error],\n",
    "                '#Avg features for test': [avg_feat],\n",
    "            }\n",
    "            # Create a DataFrame from the dictionary\n",
    "            df = pd.DataFrame(data)\n",
    "            # Specify the name of the Excel file\n",
    "            excel_file = f'Single_Run_Avg_{avg_run}_{dataset_name}.xlsx'\n",
    "            # Write the DataFrame to an Excel file\n",
    "            df.to_excel(excel_file, index=False)\n",
    "            print(f'Data successfully written to {excel_file}')\n",
    "\n",
    "        \n",
    "        #print(len(pareto_front_solutions))\n",
    "#         for solution in pareto_front_solutions:\n",
    "#                 feature_frequency += solution\n",
    "\n",
    "        \n",
    "\n",
    "# # Print the frequency of each feature being selected\n",
    "# j=0;\n",
    "# m=0;\n",
    "\n",
    "# # Create pairs of (feature, frequency)\n",
    "# feature_frequency_pairs = list(enumerate(feature_frequency))\n",
    "\n",
    "# # Sort the pairs based on frequency in descending order\n",
    "# sorted_feature_frequency_pairs = sorted(feature_frequency_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# #Get the top 100 pairs\n",
    "# top_100_feature_frequency_pairs = sorted_feature_frequency_pairs[:100]\n",
    "# frequencies_data = []\n",
    "# freq_frequencies=[]\n",
    "# print(\"Feature selection frequency for 10 run:\")\n",
    "# for i, (feature, frequency) in enumerate(top_100_feature_frequency_pairs):\n",
    "#     if(frequency>0):\n",
    "#         print(f\"Feature {feature}: {frequency} times\")\n",
    "#         frequencies_data.append(f'Feature {feature}: {frequency} times')\n",
    "#         freq_frequencies.append(f'Feature {feature},{frequency} times')\n",
    "#         m += 1\n",
    "# frequencies_data = np.array(frequencies_data, dtype=object)        \n",
    "# file_path = os.path.join(save_dir, f'Freq_{dataset_name}_.npy')\n",
    "# np.save(file_path,frequencies_data)\n",
    "# print(\"No. of Features:\",m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e204f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74bff74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_run 10\n",
      "run 1\n",
      "avg_run 10\n",
      "run 2\n",
      "avg_run 10\n",
      "run 3\n",
      "avg_run 10\n",
      "run 4\n",
      "avg_run 10\n",
      "run 5\n",
      "avg_run 10\n",
      "run 6\n",
      "avg_run 10\n",
      "run 7\n",
      "avg_run 10\n",
      "run 8\n",
      "avg_run 10\n",
      "run 9\n",
      "avg_run 10\n",
      "run 10\n",
      "Feature selection frequency for 10 runs:\n",
      "Feature 2585: 15 times\n",
      "Feature 3035: 15 times\n",
      "Feature 2930: 11 times\n",
      "Feature 1086: 10 times\n",
      "Feature 1832: 10 times\n",
      "Feature 5473: 10 times\n",
      "Feature 1736: 9 times\n",
      "Feature 2074: 9 times\n",
      "Feature 4842: 9 times\n",
      "Feature 101: 8 times\n",
      "Feature 3254: 8 times\n",
      "Feature 4005: 8 times\n",
      "Feature 5363: 8 times\n",
      "Feature 0: 7 times\n",
      "Feature 355: 7 times\n",
      "Feature 2645: 7 times\n",
      "Feature 3353: 7 times\n",
      "Feature 3652: 7 times\n",
      "Feature 4008: 7 times\n",
      "Feature 4553: 7 times\n",
      "No. of Features: 20\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'pareto_solutions'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "feat_num = 5966 \n",
    "n=10\n",
    "for avg_run in range(n,n+1):\n",
    "    feature_frequency = np.zeros(feat_num, dtype=int)\n",
    "    for run in range(1, 10 + 1):\n",
    "        # Load the Pareto front binary vectors from the file\n",
    "        print('avg_run', avg_run)\n",
    "        print('run', run)\n",
    "        file_path = os.path.join(save_dir, f'pareto_front_solutions_run_{avg_run}_{run}_{dataset_name}.npy')\n",
    "        pareto_front_solutions = np.load(file_path)\n",
    "\n",
    "        for solution in pareto_front_solutions:\n",
    "            feature_frequency += solution\n",
    "\n",
    "    # After completing 10 runs, print the frequency of each feature being selected\n",
    "    feature_frequency_pairs = list(enumerate(feature_frequency))\n",
    "\n",
    "    # Sort the pairs based on frequency in descending order\n",
    "    sorted_feature_frequency_pairs = sorted(feature_frequency_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 100 pairs\n",
    "    top_100_feature_frequency_pairs = sorted_feature_frequency_pairs[:20]\n",
    "    frequencies_data = []\n",
    "    freq_frequencies = []\n",
    "\n",
    "    print(\"Feature selection frequency for 10 runs:\")\n",
    "    m = 0\n",
    "    for i, (feature, frequency) in enumerate(top_100_feature_frequency_pairs):\n",
    "        if frequency > 0:\n",
    "            print(f\"Feature {feature}: {frequency} times\")\n",
    "            frequencies_data.append(f'Feature {feature}: {frequency} times')\n",
    "            m += 1\n",
    "\n",
    "    frequencies_data = np.array(frequencies_data, dtype=object)\n",
    "    file_path = os.path.join(save_dir, f'Freq_{dataset_name}_run_{avg_run}.npy')\n",
    "    np.save(file_path, frequencies_data)\n",
    "    print(\"No. of Features:\", m)\n",
    "\n",
    "        \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54f4d416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8709677419354839\n",
      "Error:0.12903225806451613\n",
      "0.8709677419354839\n",
      "2\n",
      "0.9032258064516129\n",
      "Error:0.09677419354838712\n",
      "0.9032258064516129\n",
      "3\n",
      "0.9032258064516129\n",
      "Error:0.09677419354838712\n",
      "0.9032258064516129\n",
      "4\n",
      "0.9032258064516129\n",
      "Error:0.09677419354838712\n",
      "0.9032258064516129\n",
      "5\n",
      "0.9032258064516129\n",
      "Error:0.09677419354838712\n",
      "0.9032258064516129\n",
      "6\n",
      "0.9032258064516129\n",
      "Error:0.09677419354838712\n",
      "0.9032258064516129\n",
      "7\n",
      "0.9032258064516129\n",
      "Error:0.09677419354838712\n",
      "0.9032258064516129\n",
      "8\n",
      "0.967741935483871\n",
      "Error:0.032258064516129004\n",
      "0.967741935483871\n",
      "9\n",
      "0.967741935483871\n",
      "Error:0.032258064516129004\n",
      "0.967741935483871\n",
      "10\n",
      "0.967741935483871\n",
      "Error:0.032258064516129004\n",
      "0.967741935483871\n",
      "11\n",
      "0.967741935483871\n",
      "Error:0.032258064516129004\n",
      "0.967741935483871\n",
      "12\n",
      "1.0\n",
      "Error:0.0\n",
      "1.0\n",
      "13\n",
      "0.9354838709677419\n",
      "Error:0.06451612903225812\n",
      "1.0\n",
      "14\n",
      "0.967741935483871\n",
      "Error:0.032258064516129004\n",
      "1.0\n",
      "15\n",
      "0.967741935483871\n",
      "Error:0.032258064516129004\n",
      "1.0\n",
      "16\n",
      "0.9354838709677419\n",
      "Error:0.06451612903225812\n",
      "1.0\n",
      "17\n",
      "0.967741935483871\n",
      "Error:0.032258064516129004\n",
      "1.0\n",
      "18\n",
      "0.9354838709677419\n",
      "Error:0.06451612903225812\n",
      "1.0\n",
      "19\n",
      "0.9354838709677419\n",
      "Error:0.06451612903225812\n",
      "1.0\n",
      "20\n",
      "0.9032258064516129\n",
      "Error:0.09677419354838712\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "    #total_feat= 7129\n",
    "    select_feat = []\n",
    "    feat_after_voting=[]\n",
    "    test_error_after_voting = []\n",
    "    with open(f'data_test{dataset_name}.pkl', 'rb') as f:\n",
    "        data_test_open = pickle.load(f)\n",
    "    X_test_vot = data_test_open['X_test']\n",
    "    Y_test_vot = data_test_open['Y_test']\n",
    "    \n",
    "\n",
    "    #print(top_100_feature_frequency_pairs);\n",
    "select_feat = [] \n",
    "acc_app= []\n",
    "    for j,(feature,frequency) in enumerate(top_100_feature_frequency_pairs):\n",
    "        if(j<m):\n",
    "            select_feat.append(feature)\n",
    "            print(len(select_feat))\n",
    "            #print(select_feat)\n",
    "            feat_after_voting.append(len(select_feat))\n",
    "            X_selected = X_train[:, select_feat]\n",
    "            testx = X_test_vot[:,select_feat]\n",
    "            knn = KNeighborsClassifier(n_neighbors=5)\n",
    "            knn.fit(X_selected, Y_train)\n",
    "            ypred = knn.predict(testx)\n",
    "            acu = accuracy_score(Y_test_vot, ypred)\n",
    "            err_voting = 1-acu\n",
    "            test_error_after_voting.append(err_voting)\n",
    "            print(acu)\n",
    "            print(f\"Error:{err_voting}\")\n",
    "            acc_app.append(acu)\n",
    "            max_acc = np.max(acc_app)\n",
    "            print(max_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5df1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
