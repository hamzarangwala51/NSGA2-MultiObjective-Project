{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1838b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pymoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('leukemia.mat')\n",
    "dataset_name = \"leukemia,72\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('colon.mat')\n",
    "dataset_name = \"colon,62\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fab0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('Prostate.mat')\n",
    "dataset_name = \"Prostate,102\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88134683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('ALLAML.mat')\n",
    "dataset_name = \"ALLAML,72\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69607e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('lymphoma.mat')\n",
    "dataset_name = \"lymphoma,96\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c756ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[1.87794695 1.30103    1.95036485 ... 2.11327469 2.60938094 3.68796571]\n",
      " [2.65103647 2.29021119 2.43658941 ... 1.92947518 2.51964518 3.9517036 ]\n",
      " [2.22110843 2.30232054 3.04513748 ... 1.30103    1.30103    3.7057659 ]\n",
      " ...\n",
      " [1.90108937 2.50788797 2.41862225 ... 1.86934873 2.28255006 3.68242461]\n",
      " [1.99002674 2.2935855  2.82733399 ... 1.30103    1.78780459 3.4468193 ]\n",
      " [2.19303105 1.30103    2.80834347 ... 1.41392477 1.63806194 3.55952576]]\n",
      "Y = [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "4434\n",
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Tue Mar 17 16:07:27 2015', '__version__': '1.0', '__globals__': [], 'X': array([[1.87794695, 1.30103   , 1.95036485, ..., 2.11327469, 2.60938094,\n",
      "        3.68796571],\n",
      "       [2.65103647, 2.29021119, 2.43658941, ..., 1.92947518, 2.51964518,\n",
      "        3.9517036 ],\n",
      "       [2.22110843, 2.30232054, 3.04513748, ..., 1.30103   , 1.30103   ,\n",
      "        3.7057659 ],\n",
      "       ...,\n",
      "       [1.90108937, 2.50788797, 2.41862225, ..., 1.86934873, 2.28255006,\n",
      "        3.68242461],\n",
      "       [1.99002674, 2.2935855 , 2.82733399, ..., 1.30103   , 1.78780459,\n",
      "        3.4468193 ],\n",
      "       [2.19303105, 1.30103   , 2.80834347, ..., 1.41392477, 1.63806194,\n",
      "        3.55952576]]), 'Y': array([[1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4]], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('GLIOMA.mat')\n",
    "dataset_name = \"Glioma,50\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('lung.mat')\n",
    "dataset_name = \"Lung,203\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260afc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_contents = scipy.io.loadmat('GLI_85.mat')\n",
    "dataset_name = \"GLI,85\"\n",
    "# Display the contents\n",
    "#print(mat_contents)\n",
    "data = mat_contents\n",
    "X = data['X']\n",
    "Y=data['Y'].ravel()\n",
    "print(\"X =\",X)\n",
    "print(\"Y =\",Y)\n",
    "print(X.shape[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io\n",
    "\n",
    "# # # Load the .mat file\n",
    "# mat_contents = scipy.io.loadmat('leukemia.mat')\n",
    "\n",
    "# # Display the contents\n",
    "# #print(mat_contents)\n",
    "# data = mat_contents\n",
    "# X = data['X']\n",
    "# Y=data['Y'].ravel()\n",
    "# print(\"X =\",X)\n",
    "# print(\"Y =\",Y)\n",
    "# print(X.shape[1])\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9ad143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from pymoo.termination import get_termination\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
    "from pymoo.operators.crossover.ux import UniformCrossover\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
    "from sklearn.preprocessing import (StandardScaler, OrdinalEncoder,LabelEncoder, MinMaxScaler, OneHotEncoder)\n",
    "from pymoo.indicators.hv import HV\n",
    "import pandas as pd\n",
    "from pymoo.core.sampling import Sampling\n",
    "import random\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d7011a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 4434), (50,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba6b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1477fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_saved = {\n",
    "    'X_test': X_test,\n",
    "    'Y_test': Y_test\n",
    "}\n",
    "with open(f'data_test{dataset_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(data_test_saved, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613cafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of classes\n",
    "def class_distribution(X):\n",
    "    unique, counts = np.unique(X, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "# Original dataset distribution\n",
    "original_dist = class_distribution(X)\n",
    "print(\"Original dataset distribution:\", original_dist)\n",
    "\n",
    "# Training set distribution\n",
    "train_dist = class_distribution(X_train)\n",
    "print(\"Training set distribution:\", train_dist)\n",
    "\n",
    "# Test set distribution\n",
    "test_dist = class_distribution(X_test)\n",
    "print(\"Test set distribution:\", test_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of classes\n",
    "def class_distribution(Y):\n",
    "    unique, counts = np.unique(Y, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "# Original dataset distribution\n",
    "original_dist = class_distribution(Y)\n",
    "print(\"Original dataset distribution:\", original_dist)\n",
    "\n",
    "# Training set distribution\n",
    "train_dist = class_distribution(Y_train)\n",
    "print(\"Training set distribution:\", train_dist)\n",
    "\n",
    "# Test set distribution\n",
    "test_dist = class_distribution(Y_test)\n",
    "print(\"Test set distribution:\", test_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProblem(Problem):\n",
    "    def __init__(self):\n",
    "        super().__init__(n_var=2000, # decision variables\n",
    "                         n_obj=2,  # two objective functions\n",
    "                        n_ieq_constr=1 \n",
    "                        )\n",
    "\n",
    "    def _classification_error(self, bitstring):\n",
    "        featureNames = []\n",
    "        for i in range(len(bitstring)):\n",
    "            if bitstring[i] == 1:\n",
    "                featureNames.append(i)\n",
    "  \n",
    "        if len(featureNames) == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            trainx = X_train[:,featureNames]\n",
    "            trainy = Y_train\n",
    "            knn = KNeighborsClassifier(n_neighbors=5)\n",
    "            knn.fit(trainx, trainy)\n",
    "            Y_pred = knn.predict(trainx)\n",
    "            ac = accuracy_score(trainy, Y_pred)\n",
    "            return 1 - ac\n",
    "\n",
    "    def _features_number(self, bitstring):\n",
    "        return sum(bitstring)\n",
    "\n",
    "    def _constrain(self,bitstring):\n",
    "        return 1 - sum(bitstring)\n",
    "    \n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        f1 = [self._features_number(x[i]) for i in range(len(x))]\n",
    "        f2 = [self._classification_error(x[i]) for i in range(len(x))]\n",
    "        g1 = [self._constrain(x[i]) for i in range(0, len(x))]\n",
    "        out[\"F\"] = np.column_stack([f1, f2])\n",
    "        out[\"G\"] = np.column_stack([g1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f6af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generate_population(Sampling):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "        def _do(self, problem, n_samples, **kwargs):\n",
    "            total_features = 22283\n",
    "            population_size = 100\n",
    "            population = []\n",
    "            for _ in range(population_size):\n",
    "                n = random.randint(1, total_features) \n",
    "                individual = [0] * total_features\n",
    "                selected_indices = random.sample(range(total_features), n)\n",
    "                for idx in selected_indices :\n",
    "                    individual[idx] = 1\n",
    "                population.append(individual)\n",
    "            return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce938d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.3, random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(xtrain, ytrain)\n",
    "ypred = knn.predict(xtrain)\n",
    "ac = accuracy_score(ytrain, ypred)\n",
    "print(ac)\n",
    "print(\"Classification error on training sets using all features: \" + str(1 - ac))\n",
    "ypred = knn.predict(xtest)\n",
    "ac = accuracy_score(ytest, ypred)\n",
    "print(ac)\n",
    "print(\"Classification error on testing sets using all features: \" + str(1 - ac))\n",
    "\n",
    "print(\"###################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2479d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem = FeatureSelectionProblem(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd469202",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = MyProblem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = NSGA2(pop_size=100,\n",
    "                  sampling=generate_population(),\n",
    "                  crossover=UniformCrossover(prob=0.9),\n",
    "                  mutation=BitflipMutation(prob=0.01),\n",
    "                  eliminate_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836733b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "termination = get_termination(\"n_gen\", 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb3f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=42,\n",
    "               save_history=True,\n",
    "               verbose=True)\n",
    "\n",
    "i_f = res.history[0].opt.get(\"F\")\n",
    "i_pop = res.history[0].pop\n",
    "f = res.F\n",
    "pop = res.pop\n",
    "pop_test = res.pop\n",
    "solutions = res.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the intial pareto front is plotted as: \")\n",
    "plt.scatter(i_pop.get(\"F\")[:,0], i_pop.get(\"F\")[:,1], edgecolor=\"blue\", facecolor=\"none\", label = \"solutions\")\n",
    "plt.scatter(i_f[:,0], i_f[:,1], marker='*', edgecolor=\"red\", facecolor=\"none\", label = \"optimal pareto front\")\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('training error')\n",
    "plt.legend()\n",
    "plt.title(\"visualization of the initial pareto front\")\n",
    "plt.show()\n",
    "print(\"the final pareto front is plotted as: \")\n",
    "plt.scatter(pop.get(\"F\")[:,0], pop.get(\"F\")[:,1], edgecolor=\"blue\", facecolor=\"none\", label = \"solutions\")\n",
    "plt.scatter(f[:,0], f[:,1], marker='*', edgecolor=\"red\", facecolor=\"none\", label = \"optimal pareto front\")\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('training error')\n",
    "plt.legend()\n",
    "plt.title(\"visualization of the final pareto front\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f72356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum error from the optimization result\n",
    "min_error_train = np.min(f[:, 1])\n",
    "\n",
    "# Print the minimum error with increased decimals\n",
    "print(\"Minimum error on training dataset: {:.10f}\".format(min_error_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaedcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(res.F[:,1])\n",
    "# print(res.F[:,0])\n",
    "# print(pop.get(\"F\")[:,0])\n",
    "# print(pop.get(\"F\")[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae28ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(X_test, Y_test, solution):\n",
    "    feature_indices = [i for i in range(len(solution)) if solution[i] == 1]\n",
    "    if len(feature_indices) == 0:\n",
    "        return [X.shape[1], 1.0]\n",
    "    else:\n",
    "        X_test_selected = X_test[:, feature_indices]\n",
    "        knn = KNeighborsClassifier(n_neighbors=5)\n",
    "        knn.fit(X_train[:, feature_indices], Y_train)\n",
    "        Y_pred = knn.predict(X_test_selected)\n",
    "        error_rate = 1 - accuracy_score(Y_test, Y_pred)\n",
    "        return [len(feature_indices), error_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each solution on the test data\n",
    "print(len(pop_test.get(\"X\")))\n",
    "print(len(res.X))\n",
    "print(pop_test.get(\"X\"))\n",
    "Solutions_test = np.array([evaluate_on_test(X_test, Y_test, solution) for solution in res.X])\n",
    "\n",
    "# Perform non-dominated sorting\n",
    "nds = NonDominatedSorting().do(Solutions_test)\n",
    "\n",
    "# Extract the Pareto front solutions\n",
    "pareto_front_indices = nds[0]\n",
    "pareto_front_objectives_test = Solutions_test[pareto_front_indices]\n",
    "\n",
    "\n",
    "# print(f\"Total number of solutions: {len(Solutions_test)}\")\n",
    "# print(f\"Number of Pareto front solutions: {len(pareto_front_indices)}\")\n",
    "# print(\"Some solutions from the last generation:\", Solutions_test[:5])\n",
    "# print(\"Pareto front solutions:\", pareto_front_objectives)\n",
    "\n",
    "\n",
    "# Plot the Pareto front graph\n",
    "print(\"The final Pareto front is plotted as:\")\n",
    "plt.scatter(Solutions_test[:, 0], Solutions_test[:, 1], edgecolor=\"blue\", facecolor=\"none\", label=\"Solutions\")\n",
    "plt.scatter(pareto_front_objectives_test[:, 0], pareto_front_objectives_test[:, 1], marker='*', edgecolor=\"red\", facecolor=\"none\", label=\"Optimal Pareto front\")\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Test Error')\n",
    "plt.legend()\n",
    "plt.title(\"Visualization of the Final Pareto Front after NDS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d56131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Pareto front for test data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(f_test[:, 0], f_test[:, 1], edgecolor=\"blue\", facecolor=\"none\", label=\"Test Data Pareto Front\")\n",
    "plt.scatter(optimal_solution[0], optimal_solution[1], marker='*', color='red', s=100, label=\"Optimal Solution\")\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.legend()\n",
    "plt.title(\"Pareto Front on Test Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a372bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point = np.array([1, 1])\n",
    "ind = HV(ref_point=ref_point)\n",
    "scaler = MinMaxScaler()\n",
    "f_train = scaler.fit_transform(f)\n",
    "hv_train = ind(f_train)\n",
    "print(\"HV of the best pareto front train:\" + str(round(hv_train, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point = np.array([1, 1])\n",
    "ind = HV(ref_point=ref_point)\n",
    "scaler = MinMaxScaler()\n",
    "f_t = scaler.fit_transform(Solutions_test)\n",
    "hv_test = ind(f_t)\n",
    "print(\"HV of the best pareto front test:\" + str(round(hv_test, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting and plotting the Pareto Front from all generations\n",
    "pareto_fronts = [gen.opt.get(\"F\") for gen in res.history]\n",
    "\n",
    "for i, pareto in enumerate(pareto_fronts):\n",
    "    plt.scatter(pareto[:, 0], pareto[:, 1])\n",
    "\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Training Error Rate')\n",
    "plt.title('Pareto Front Evolution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e7f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum error from the optimization result\n",
    "min_error_test = np.min(Solutions_test[:,1])\n",
    "\n",
    "# Print the minimum error\n",
    "print(\"Minimum error on testing dataset:\", min_error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d10d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum error from the optimization result\n",
    "min_error_train = np.min(res.F[:, 1])\n",
    "\n",
    "# Find the row(s) where the error is minimized\n",
    "min_error_indices = np.where(res.F[:, 1] == min_error_train)[0]\n",
    "\n",
    "# Get the corresponding solutions with minimum error\n",
    "solutions_with_min_error = res.X[min_error_indices]\n",
    "\n",
    "# Get the number of features for the solutions with minimum error\n",
    "num_features_with_min_error_train = [np.count_nonzero(solution) for solution in solutions_with_min_error]\n",
    "\n",
    "# Print the number of features with minimum error\n",
    "print(\"Number of features with minimum error on train:\", num_features_with_min_error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_with_min_error_test = np.min(Solutions_test[:,0])\n",
    "print(\"Number of features with minimum error on test data:\",num_features_with_min_error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c804f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Create a PrettyTable instance\n",
    "table = PrettyTable()\n",
    "\n",
    "# Set the column alignment\n",
    "table.align = \"l\"\n",
    "\n",
    "# Define the column names\n",
    "table.field_names = [\"Info abt. Db\", \"H.V.(Train)\", \"H.V.(Test)\", \n",
    "                     \"Min. Error(Train)\", \"Min. Err(Test)\", \"Feat.w Min.Err(Trn.)\", \n",
    "                     \"Feat.w Min.Err(Tst)\"]\n",
    "\n",
    "# Populate the table with data\n",
    "dataset_info = \"Lukemia,72,7070\"\n",
    "dataset_name = \"Lukemia\"\n",
    "hv_training = \"{:.2f}\".format(hv_train)\n",
    "hv_testing = \"{:.2f}\".format(hv_test)\n",
    "min_error_training = \"{:.5f}\".format(min_error_train)\n",
    "min_error_testing = \"{:.5f}\".format(min_error_test)\n",
    "min_error_features_training = num_features_with_min_error_train[0]\n",
    "min_error_features_testing = num_features_with_min_error_test\n",
    "\n",
    "\n",
    "# Add data to the table row\n",
    "table.add_row([dataset_info, hv_training, hv_testing, min_error_training, min_error_testing,\n",
    "               min_error_features_training, min_error_features_testing])\n",
    "\n",
    "\n",
    "# Print the table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4abd7f",
   "metadata": {},
   "source": [
    "# (TRAIN + Validation ) For Voting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProblem_Split(Problem):\n",
    "    def __init__(self, X_train1,Y_train1):\n",
    "        super().__init__(n_var=22283,  # decision variables\n",
    "                         n_obj=2,    # two objective functions\n",
    "                         n_ieq_constr=1  # one inequality constraint\n",
    "                        )\n",
    "        self.X_train1 = X_train1\n",
    "        self.Y_train1 = Y_train1\n",
    "\n",
    "    def _classification_error(self, bitstring):\n",
    "        featureNames = [i for i in range(len(bitstring)) if bitstring[i] == 1]\n",
    "        \n",
    "        if len(featureNames) == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            trainx = self.X_train1[:, featureNames]\n",
    "            trainy = self.Y_train1\n",
    "            knn = KNeighborsClassifier(n_neighbors=5)\n",
    "            knn.fit(trainx, trainy)\n",
    "            Y_pred = knn.predict(trainx)\n",
    "            ac = accuracy_score(trainy, Y_pred)\n",
    "            return 1 - ac\n",
    "\n",
    "    def _features_number(self, bitstring):\n",
    "        return sum(bitstring)\n",
    "\n",
    "    def _constrain(self, bitstring):\n",
    "        return 1 - sum(bitstring)\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        f1 = [self._features_number(x[i]) for i in range(len(x))]\n",
    "        f2 = [self._classification_error(x[i]) for i in range(len(x))]\n",
    "        g1 = [self._constrain(x[i]) for i in range(0, len(x))]\n",
    "        out[\"F\"] = np.column_stack([f1, f2])\n",
    "        out[\"G\"] = np.column_stack([g1])\n",
    "        \n",
    "# def evaluate_on_valid_data(X, Y, solution):\n",
    "#     feature_indices = [i for i in range(len(solution)) if solution[i] == 1]\n",
    "#     if len(feature_indices) == 0:\n",
    "#         return [X_test.shape[1], 1.0]\n",
    "#     else:\n",
    "#         X_selected = X_train[:, feature_indices]\n",
    "#         testx = X[:,feature_indices]\n",
    "#         knn = KNeighborsClassifier(n_neighbors=5)\n",
    "#         knn.fit(X_selected, Y_train)\n",
    "#         ypred = knn.predict(testx)\n",
    "#         ac = accuracy_score(ytest, ypred)\n",
    "#         error_rate = 1 - ac\n",
    "#         return [len(feature_indices), error_rate]\n",
    "def evaluate_on_valid_data(X_train, Y_train, X_valid, Y_valid, solution):\n",
    "    feature_indices = [i for i in range(len(solution)) if solution[i] == 1]\n",
    "    if len(feature_indices) == 0:\n",
    "        return [X_valid.shape[1], 1.0,np.zeros_like(solution)]\n",
    "    else:\n",
    "        X_selected = X_train[:, feature_indices]\n",
    "        X_valid_selected = X_valid[:, feature_indices]\n",
    "        knn = KNeighborsClassifier(n_neighbors=5)\n",
    "        knn.fit(X_selected, Y_train)\n",
    "        y_pred = knn.predict(X_valid_selected)\n",
    "        ac = accuracy_score(Y_valid, y_pred)\n",
    "        error_rate = 1 - ac\n",
    "        return [len(feature_indices), error_rate,solution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3d643",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Directory to save the solutions\n",
    "save_dir = 'pareto_solutions'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=None)\n",
    "fold_iterator = kfold.split(X_train, Y_train)\n",
    "err_avg=[]\n",
    "avg_min_train_error= []\n",
    "min_err_validation=[]\n",
    "k=[]\n",
    "# Loop for 10 runs\n",
    "for run in range(1, 10+1):\n",
    "#for run in range(0, 1):\n",
    "    print(f\"Run {run}:\")\n",
    "    train_indices, test_indices = next(fold_iterator)\n",
    "    X_train1, X_valid1 = X_train[train_indices], X_train[test_indices]\n",
    "    Y_train1, Y_valid1 = Y_train[train_indices], Y_train[test_indices]\n",
    "    print(X_train1.shape,X_valid1.shape,Y_train1.shape, Y_valid1.shape)\n",
    "    #print(X_train.shape, Y_train.shape)\n",
    "    #X_train1, X_valid1, Y_train1, Y_valid1 = train_test_split(X_train, Y_train, test_size=0.3, random_state=None)\n",
    "    problem_split = MyProblem_Split(X_train1,Y_train1)\n",
    "    algorithm = NSGA2(pop_size=100,\n",
    "                  sampling=generate_population(),\n",
    "                  crossover=UniformCrossover(prob=0.9),\n",
    "                  mutation=BitflipMutation(prob=0.01),\n",
    "                  eliminate_duplicates=True)\n",
    "    termination = get_termination(\"n_gen\", 50)\n",
    "    res = minimize(problem_split,\n",
    "                   algorithm,\n",
    "                   termination,\n",
    "                   seed=42,\n",
    "                   save_history=True,\n",
    "                   verbose=False)\n",
    "\n",
    "    i_f = res.history[0].opt.get(\"F\")\n",
    "    i_pop = res.history[0].pop\n",
    "    f = res.F\n",
    "    pop = res.pop\n",
    "    pop_valid = res.pop\n",
    "    solutions = res.X\n",
    "    print(\"the intial pareto front is plotted as: \")\n",
    "    plt.scatter(i_pop.get(\"F\")[:,0], i_pop.get(\"F\")[:,1], edgecolor=\"blue\", facecolor=\"none\", label = \"solutions\")\n",
    "    plt.scatter(i_f[:,0], i_f[:,1], marker='*', edgecolor=\"red\", facecolor=\"none\", label = \"optimal pareto front\")\n",
    "    plt.xlabel('number of features')\n",
    "    plt.ylabel('training error')\n",
    "    plt.legend()\n",
    "    plt.title(\"visualization of the initial pareto front\")\n",
    "    plt.show()\n",
    "    print(\"the final pareto front is plotted as: \")\n",
    "    plt.scatter(pop.get(\"F\")[:,0], pop.get(\"F\")[:,1], edgecolor=\"blue\", facecolor=\"none\", label = \"solutions\")\n",
    "    plt.scatter(f[:,0], f[:,1], marker='*', edgecolor=\"red\", facecolor=\"none\", label = \"optimal pareto front\")\n",
    "    plt.xlabel('number of features')\n",
    "    plt.ylabel('training error')\n",
    "    plt.legend()\n",
    "    plt.title(\"visualization of the final pareto front\")\n",
    "    plt.show()\n",
    "\n",
    "    avg_min_train_error.append(np.min(f[:,1]))\n",
    "    avg_err_train=np.mean(avg_min_train_error)\n",
    "    print(avg_err_train)\n",
    "    # Evaluate each solution on the validation data \n",
    "    results = [evaluate_on_valid_data(X_train1, Y_train1, X_valid1, Y_valid1, solution) for solution in res.X]    \n",
    "    \n",
    "    \n",
    "    # Separate the main results and binary vectors\n",
    "    Solutions_valid = np.array([result[:2] for result in results])\n",
    "    binary_vectors = [result[2] for result in results]\n",
    "    \n",
    "    \n",
    "    # Perform non-dominated sorting\n",
    "    nds = NonDominatedSorting().do(Solutions_valid)\n",
    "    \n",
    "    \n",
    "    # Extract the Pareto front solutions\n",
    "    pareto_front_indices = nds[0]\n",
    "    pareto_front_objectives = Solutions_valid[pareto_front_indices]\n",
    "    \n",
    "    \n",
    "    non_dominated_binary_vectors = [binary_vectors[i] for i in pareto_front_indices]\n",
    "    \n",
    "    print(non_dominated_binary_vectors)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save the Pareto front binary vectors to a file\n",
    "    file_path = os.path.join(save_dir, f'pareto_front_solutions_run_{run}_{dataset_name}.npy')\n",
    "    np.save(file_path, non_dominated_binary_vectors)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the Pareto front graph\n",
    "    print(\"The final Pareto front is plotted as:\")\n",
    "    plt.scatter(Solutions_valid[:, 0], Solutions_valid[:, 1], edgecolor=\"blue\", facecolor=\"none\", label=\"Solutions\")\n",
    "    plt.scatter(pareto_front_objectives[:, 0], pareto_front_objectives[:, 1], marker='*', edgecolor=\"red\", facecolor=\"none\", label=\"Optimal Pareto front\")\n",
    "    plt.xlabel('Number of Features')\n",
    "    plt.ylabel('Test Error')\n",
    "    plt.legend()\n",
    "    plt.title(\"Visualization of the Pareto Front on Validate set\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    min_err_validation.append(np.min(pareto_front_objectives[:, 1]))\n",
    "    avg_min_error_valid=np.mean(min_err_validation)\n",
    "    \n",
    "    with open(f'data_test{dataset_name}.pkl', 'rb') as f:\n",
    "        data_test_open = pickle.load(f)\n",
    "    X_test_open = data_test_open['X_test']\n",
    "    Y_test_open = data_test_open['Y_test']\n",
    "    \n",
    "    \n",
    "    for idx, vector in enumerate(non_dominated_binary_vectors):\n",
    "        low_error=np.min(Solutions_valid[:,1])\n",
    "        feature_no=np.where(low_error==Solutions_valid[:,1])[0]\n",
    "        feature_index = [i for i in range(len(vector)) if vector[i] == 1]\n",
    "        for i,f in Solutions_valid[feature_no]:\n",
    "            if(i==len(feature_index)):\n",
    "                print(f\"Non-dominated binary vector with {len(feature_index)} features:\")\n",
    "                k.append(len(feature_index))\n",
    "                avg_feat_evry_run = np.mean(k)\n",
    "                print(np.mean(k))\n",
    "                print(feature_index)\n",
    "                selected_features = feature_index\n",
    "                X_selected = X_train[:, selected_features]\n",
    "                testx = X_test_open[:,selected_features]\n",
    "                knn = KNeighborsClassifier(n_neighbors=5)\n",
    "                knn.fit(X_selected, Y_train)\n",
    "                ypred = knn.predict(testx)\n",
    "                ac = accuracy_score(Y_test_open, ypred)\n",
    "                err_test = 1-ac\n",
    "                err_avg.append(err_test)\n",
    "                print(ac)\n",
    "                #print(acc_avg)\n",
    "                test_err = np.mean(err_avg)\n",
    "                print(np.mean(err_avg))\n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13786e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     free=np.min(pareto_front_objectives[:,1])\n",
    "#     # Find the row(s) where the error is minimized\n",
    "#     min_error_indices = np.where(free==pareto_front_objectives[:,1])[0]\n",
    "#     print(pareto_front_objectives[min_error_indices])\n",
    "#     #print(pareto_front_solutions[min_error_indices].flatten())\n",
    "    \n",
    "    \n",
    "#     l=0;\n",
    "#     for i in pareto_front_solutions[min_error_indices]:\n",
    "#         for j in i:\n",
    "#             if(j==1):\n",
    "#                 l+=j;     \n",
    "#     print(l)\n",
    "        #print(i)\n",
    "    #print(pareto_front_solutions[min_error_indices])\n",
    "    #print(min_error_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8208f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_avg=[]\n",
    "# for i in range(0,10):\n",
    "#     selected_features = pareto_front_solutions[min_error_indices].flatten()\n",
    "#     X_selected = X_train[:, selected_features]\n",
    "#     testx = X_test[:,selected_features]\n",
    "#     #print(X_selected)\n",
    "#     knn = KNeighborsClassifier(n_neighbors=5)\n",
    "#     knn.fit(X_selected, Y_train)\n",
    "#     ypred = knn.predict(testx)\n",
    "#     ac = accuracy_score(ytest, ypred)\n",
    "#     acc_avg.append(ac)\n",
    "#     print(ac)\n",
    "# print(acc_avg)\n",
    "# print(np.mean(acc_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e95648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection frequency across 10 runs:\n",
      "Feature 404: 12 times\n",
      "Feature 1643: 11 times\n",
      "Feature 1656: 11 times\n",
      "Feature 515: 10 times\n",
      "Feature 3762: 10 times\n",
      "Feature 1707: 9 times\n",
      "Feature 4300: 9 times\n",
      "Feature 3374: 8 times\n",
      "Feature 274: 7 times\n",
      "Feature 974: 7 times\n",
      "Feature 2052: 7 times\n",
      "Feature 2118: 7 times\n",
      "Feature 2418: 7 times\n",
      "Feature 2521: 7 times\n",
      "Feature 2841: 7 times\n",
      "Feature 2876: 7 times\n",
      "Feature 3007: 7 times\n",
      "Feature 3344: 7 times\n",
      "Feature 63: 6 times\n",
      "Feature 502: 6 times\n",
      "Feature 1201: 6 times\n",
      "Feature 1587: 6 times\n",
      "Feature 2161: 6 times\n",
      "Feature 2315: 6 times\n",
      "Feature 2606: 6 times\n",
      "Feature 3171: 6 times\n",
      "Feature 3346: 6 times\n",
      "Feature 599: 5 times\n",
      "Feature 1229: 5 times\n",
      "Feature 1301: 5 times\n",
      "Feature 1669: 5 times\n",
      "Feature 1876: 5 times\n",
      "Feature 2035: 5 times\n",
      "Feature 2192: 5 times\n",
      "Feature 2465: 5 times\n",
      "Feature 3533: 5 times\n",
      "Feature 361: 4 times\n",
      "Feature 574: 4 times\n",
      "Feature 1240: 4 times\n",
      "Feature 1597: 4 times\n",
      "Feature 2698: 4 times\n",
      "Feature 2968: 4 times\n",
      "Feature 3207: 4 times\n",
      "Feature 3623: 4 times\n",
      "Feature 4038: 4 times\n",
      "Feature 4123: 4 times\n",
      "Feature 1: 3 times\n",
      "Feature 206: 3 times\n",
      "Feature 278: 3 times\n",
      "Feature 550: 3 times\n",
      "Feature 847: 3 times\n",
      "Feature 1565: 3 times\n",
      "Feature 1677: 3 times\n",
      "Feature 4059: 3 times\n",
      "Feature 458: 2 times\n",
      "Feature 870: 2 times\n",
      "Feature 895: 2 times\n",
      "Feature 1094: 2 times\n",
      "Feature 1285: 2 times\n",
      "Feature 1526: 2 times\n",
      "Feature 1539: 2 times\n",
      "Feature 1740: 2 times\n",
      "Feature 2111: 2 times\n",
      "Feature 2536: 2 times\n",
      "Feature 3219: 2 times\n",
      "Feature 3320: 2 times\n",
      "Feature 3920: 2 times\n",
      "Feature 402: 1 times\n",
      "Feature 930: 1 times\n",
      "Feature 985: 1 times\n",
      "Feature 1049: 1 times\n",
      "Feature 1180: 1 times\n",
      "Feature 1185: 1 times\n",
      "Feature 1193: 1 times\n",
      "Feature 1213: 1 times\n",
      "Feature 1343: 1 times\n",
      "Feature 1344: 1 times\n",
      "Feature 1385: 1 times\n",
      "Feature 1469: 1 times\n",
      "Feature 1803: 1 times\n",
      "Feature 1983: 1 times\n",
      "Feature 2290: 1 times\n",
      "Feature 2638: 1 times\n",
      "Feature 2748: 1 times\n",
      "Feature 2783: 1 times\n",
      "Feature 2978: 1 times\n",
      "Feature 3016: 1 times\n",
      "Feature 3120: 1 times\n",
      "Feature 3185: 1 times\n",
      "Feature 3201: 1 times\n",
      "Feature 3364: 1 times\n",
      "Feature 3730: 1 times\n",
      "Feature 3852: 1 times\n",
      "Feature 3904: 1 times\n",
      "Feature 3917: 1 times\n",
      "Feature 4023: 1 times\n",
      "No. of Features: 96\n"
     ]
    }
   ],
   "source": [
    "# Load the Pareto front binary vectors from files and perform voting\n",
    "\n",
    "save_dir = 'pareto_solutions'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "feature_frequency = np.zeros(4434, dtype=int)\n",
    "\n",
    "for run in range(1, 10 + 1):\n",
    "    # Load the Pareto front binary vectors from the file\n",
    "    file_path = os.path.join(save_dir, f'pareto_front_solutions_run_{run}_{dataset_name}.npy')\n",
    "    pareto_front_solutions = np.load(file_path)\n",
    "    #print(len(pareto_front_solutions))\n",
    "    for solution in pareto_front_solutions:\n",
    "            feature_frequency += solution\n",
    "    \n",
    "\n",
    "# Print the frequency of each feature being selected\n",
    "j=0;\n",
    "m=0;\n",
    "\n",
    "# Create pairs of (feature, frequency)\n",
    "feature_frequency_pairs = list(enumerate(feature_frequency))\n",
    "\n",
    "# Sort the pairs based on frequency in descending order\n",
    "sorted_feature_frequency_pairs = sorted(feature_frequency_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Get the top 100 pairs\n",
    "top_100_feature_frequency_pairs = sorted_feature_frequency_pairs[:100]\n",
    "frequencies_data = []\n",
    "freq_frequencies=[]\n",
    "print(\"Feature selection frequency across 10 runs:\")\n",
    "for i, (feature, frequency) in enumerate(top_100_feature_frequency_pairs):\n",
    "    if(frequency>0):\n",
    "        print(f\"Feature {feature}: {frequency} times\")\n",
    "        frequencies_data.append(f'Feature {feature}: {frequency} times')\n",
    "        freq_frequencies.append(f'Feature {feature},{frequency} times')\n",
    "        m += 1\n",
    "frequencies_data = np.array(frequencies_data, dtype=object)        \n",
    "file_path = os.path.join(save_dir, f'Freq_{dataset_name}_.npy')\n",
    "np.save(file_path,frequencies_data)\n",
    "print(\"No. of Features:\",m);\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79847a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert frequencies_data to a DataFrame\n",
    "df = pd.DataFrame(freq_frequencies, columns=[f\"Freq_features_{dataset_name}\"])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "file_path_excel = os.path.join(save_dir, f'Frequent_freq_{dataset_name}_.xlsx')\n",
    "df.to_excel(file_path_excel, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14d1aaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[404]\n",
      "0.4\n",
      "Error:0.6\n",
      "0.4\n",
      "2\n",
      "[404, 1643]\n",
      "0.5333333333333333\n",
      "Error:0.4666666666666667\n",
      "0.5333333333333333\n",
      "3\n",
      "[404, 1643, 1656]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.6\n",
      "4\n",
      "[404, 1643, 1656, 515]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.6666666666666666\n",
      "5\n",
      "[404, 1643, 1656, 515, 3762]\n",
      "0.8\n",
      "Error:0.19999999999999996\n",
      "0.8\n",
      "6\n",
      "[404, 1643, 1656, 515, 3762, 1707]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8\n",
      "7\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300]\n",
      "0.4666666666666667\n",
      "Error:0.5333333333333333\n",
      "0.8\n",
      "8\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374]\n",
      "0.5333333333333333\n",
      "Error:0.4666666666666667\n",
      "0.8\n",
      "9\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274]\n",
      "0.5333333333333333\n",
      "Error:0.4666666666666667\n",
      "0.8\n",
      "10\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8\n",
      "11\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8\n",
      "12\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8\n",
      "13\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418]\n",
      "0.8\n",
      "Error:0.19999999999999996\n",
      "0.8\n",
      "14\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.8666666666666667\n",
      "15\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.8666666666666667\n",
      "16\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876]\n",
      "0.8\n",
      "Error:0.19999999999999996\n",
      "0.8666666666666667\n",
      "17\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007]\n",
      "0.8\n",
      "Error:0.19999999999999996\n",
      "0.8666666666666667\n",
      "18\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344]\n",
      "0.8\n",
      "Error:0.19999999999999996\n",
      "0.8666666666666667\n",
      "19\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63]\n",
      "0.8\n",
      "Error:0.19999999999999996\n",
      "0.8666666666666667\n",
      "20\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "21\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "22\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "23\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "24\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "25\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "26\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "27\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "28\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "29\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "30\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "31\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "32\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "33\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "34\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192]\n",
      "0.8\n",
      "Error:0.19999999999999996\n",
      "0.8666666666666667\n",
      "35\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465]\n",
      "0.8\n",
      "Error:0.19999999999999996\n",
      "0.8666666666666667\n",
      "36\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "37\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "38\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "39\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "40\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "41\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "42\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "43\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "44\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "45\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "46\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "47\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "48\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "49\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "50\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "51\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "52\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "53\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "54\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "55\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "56\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "57\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "58\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "59\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "60\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "61\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "62\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "63\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "64\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "65\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "66\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320]\n",
      "0.6\n",
      "Error:0.4\n",
      "0.8666666666666667\n",
      "67\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "68\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "69\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "70\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "71\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "72\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "73\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "74\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "75\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "76\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343]\n",
      "0.6666666666666666\n",
      "Error:0.33333333333333337\n",
      "0.8666666666666667\n",
      "77\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "78\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "79\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "80\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "81\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "82\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290]\n",
      "0.7333333333333333\n",
      "Error:0.2666666666666667\n",
      "0.8666666666666667\n",
      "83\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.8666666666666667\n",
      "84\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.8666666666666667\n",
      "85\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.8666666666666667\n",
      "86\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.8666666666666667\n",
      "87\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.8666666666666667\n",
      "88\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016, 3120]\n",
      "0.9333333333333333\n",
      "Error:0.06666666666666665\n",
      "0.9333333333333333\n",
      "89\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016, 3120, 3185]\n",
      "0.9333333333333333\n",
      "Error:0.06666666666666665\n",
      "0.9333333333333333\n",
      "90\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016, 3120, 3185, 3201]\n",
      "0.9333333333333333\n",
      "Error:0.06666666666666665\n",
      "0.9333333333333333\n",
      "91\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016, 3120, 3185, 3201, 3364]\n",
      "0.9333333333333333\n",
      "Error:0.06666666666666665\n",
      "0.9333333333333333\n",
      "92\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016, 3120, 3185, 3201, 3364, 3730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "Error:0.06666666666666665\n",
      "0.9333333333333333\n",
      "93\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016, 3120, 3185, 3201, 3364, 3730, 3852]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.9333333333333333\n",
      "94\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016, 3120, 3185, 3201, 3364, 3730, 3852, 3904]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.9333333333333333\n",
      "95\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016, 3120, 3185, 3201, 3364, 3730, 3852, 3904, 3917]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.9333333333333333\n",
      "96\n",
      "[404, 1643, 1656, 515, 3762, 1707, 4300, 3374, 274, 974, 2052, 2118, 2418, 2521, 2841, 2876, 3007, 3344, 63, 502, 1201, 1587, 2161, 2315, 2606, 3171, 3346, 599, 1229, 1301, 1669, 1876, 2035, 2192, 2465, 3533, 361, 574, 1240, 1597, 2698, 2968, 3207, 3623, 4038, 4123, 1, 206, 278, 550, 847, 1565, 1677, 4059, 458, 870, 895, 1094, 1285, 1526, 1539, 1740, 2111, 2536, 3219, 3320, 3920, 402, 930, 985, 1049, 1180, 1185, 1193, 1213, 1343, 1344, 1385, 1469, 1803, 1983, 2290, 2638, 2748, 2783, 2978, 3016, 3120, 3185, 3201, 3364, 3730, 3852, 3904, 3917, 4023]\n",
      "0.8666666666666667\n",
      "Error:0.1333333333333333\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "    total_feat= 4434\n",
    "    select_feat = []\n",
    "    feat_after_voting=[]\n",
    "    test_error_after_voting = []\n",
    "    with open(f'data_test{dataset_name}.pkl', 'rb') as f:\n",
    "        data_test_open = pickle.load(f)\n",
    "    X_test_vot = data_test_open['X_test']\n",
    "    Y_test_vot = data_test_open['Y_test']\n",
    "    \n",
    "\n",
    "    #print(top_100_feature_frequency_pairs);\n",
    "select_feat = [] \n",
    "acc_app= []\n",
    "    for j,(feature,frequency) in enumerate(top_100_feature_frequency_pairs):\n",
    "        if(j<m):\n",
    "            select_feat.append(feature)\n",
    "            print(len(select_feat))\n",
    "            print(select_feat)\n",
    "            feat_after_voting.append(len(select_feat))\n",
    "            X_selected = X_train[:, select_feat]\n",
    "            testx = X_test_vot[:,select_feat]\n",
    "            knn = KNeighborsClassifier(n_neighbors=5)\n",
    "            knn.fit(X_selected, Y_train)\n",
    "            ypred = knn.predict(testx)\n",
    "            acu = accuracy_score(Y_test_vot, ypred)\n",
    "            err_voting = 1-acu\n",
    "            test_error_after_voting.append(err_voting)\n",
    "            print(acu)\n",
    "            print(f\"Error:{err_voting}\")\n",
    "            acc_app.append(acu)\n",
    "            max_acc = np.max(acc_app)\n",
    "            print(max_acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d7ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,frequency in enumerate(feature_frequency):\n",
    "    if(frequency>0):\n",
    "        print(f\"Feature {i}: {frequency} times\")\n",
    "        j += 1\n",
    "print(\"No. of Features:\",j);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where keys are column names and values are the variables\n",
    "data = {\n",
    "    'Dataset': dataset_name,\n",
    "    '#features':total_feat ,\n",
    "    'Avg. of Min train error': avg_err_train,\n",
    "    'Avg. of Min validation error':avg_min_error_valid,\n",
    "    'Avg. of test error for every run':test_err,\n",
    "    '#features for test':avg_feat_evry_run,\n",
    "    'Test error after voting': test_error_after_voting,\n",
    "    '#features for test after voting':feat_after_voting\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Specify the name of the Excel file\n",
    "excel_file = f'output_{dataset_name}.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f'Data successfully written to {excel_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb428e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    #dataset_name = \"lukemia\"\n",
    "    file_path = os.path.join(save_dir, f'Freq_{dataset_name}_.npy')\n",
    "    frequencies_data = np.load(file_path, allow_pickle=True)\n",
    "        # Display the loaded data\n",
    "    print(frequencies_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(frequencies_data)\n",
    "\n",
    "# Define the Excel file path\n",
    "excel_file_path = os.path.join(save_dir, f'Freq_{dataset_name}.xlsx')\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f'Data has been saved to {excel_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b68021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1.shape, X_valid1.shape, Y_train1.shape, Y_valid1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52b559",
   "metadata": {},
   "outputs": [],
   "source": [
    " class MyProblem_Split(Problem):\n",
    "    def __init__(self):\n",
    "        super().__init__(n_var=7070, # decision variables\n",
    "                         n_obj=2,  # two objective functions\n",
    "                        n_ieq_constr=1 \n",
    "                        )\n",
    "\n",
    "    def _classification_error(self, bitstring):\n",
    "        featureNames = []\n",
    "        for i in range(len(bitstring)):\n",
    "            if bitstring[i] == 1:\n",
    "                featureNames.append(i)\n",
    "  \n",
    "        if len(featureNames) == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            trainx = X_train1[:,featureNames]\n",
    "            trainy = Y_train1\n",
    "            knn = KNeighborsClassifier(n_neighbors=5)\n",
    "            knn.fit(trainx, trainy)\n",
    "            Y_pred = knn.predict(trainx)\n",
    "            ac = accuracy_score(trainy, Y_pred)\n",
    "            return 1 - ac\n",
    "\n",
    "    def _features_number(self, bitstring):\n",
    "        return sum(bitstring)\n",
    "\n",
    "    def _constrain(self,bitstring):\n",
    "        return 1 - sum(bitstring)\n",
    "    \n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        f1 = [self._features_number(x[i]) for i in range(len(x))]\n",
    "        f2 = [self._classification_error(x[i]) for i in range(len(x))]\n",
    "        g1 = [self._constrain(x[i]) for i in range(0, len(x))]\n",
    "        out[\"F\"] = np.column_stack([f1, f2])\n",
    "        out[\"G\"] = np.column_stack([g1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0450f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_split = MyProblem_Split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae461276",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = NSGA2(pop_size=100,\n",
    "                  sampling=generate_population(),\n",
    "                  crossover=UniformCrossover(prob=0.9),\n",
    "                  mutation=BitflipMutation(prob=0.01),\n",
    "                  eliminate_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "termination = get_termination(\"n_gen\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(problem_split,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=42,\n",
    "               save_history=True,\n",
    "               verbose=True)\n",
    "\n",
    "i_f = res.history[0].opt.get(\"F\")\n",
    "i_pop = res.history[0].pop\n",
    "f = res.F\n",
    "pop = res.pop\n",
    "pop_valid = res.pop\n",
    "solutions = res.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd276abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the intial pareto front is plotted as: \")\n",
    "plt.scatter(i_pop.get(\"F\")[:,0], i_pop.get(\"F\")[:,1], edgecolor=\"blue\", facecolor=\"none\", label = \"solutions\")\n",
    "plt.scatter(i_f[:,0], i_f[:,1], marker='*', edgecolor=\"red\", facecolor=\"none\", label = \"optimal pareto front\")\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('training error')\n",
    "plt.legend()\n",
    "plt.title(\"visualization of the initial pareto front\")\n",
    "plt.show()\n",
    "print(\"the final pareto front is plotted as: \")\n",
    "plt.scatter(pop.get(\"F\")[:,0], pop.get(\"F\")[:,1], edgecolor=\"blue\", facecolor=\"none\", label = \"solutions\")\n",
    "plt.scatter(f[:,0], f[:,1], marker='*', edgecolor=\"red\", facecolor=\"none\", label = \"optimal pareto front\")\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('training error')\n",
    "plt.legend()\n",
    "plt.title(\"visualization of the final pareto front\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_valid_data(X, Y, solution):\n",
    "    feature_indices = [i for i in range(len(solution)) if solution[i] == 1]\n",
    "    if len(feature_indices) == 0:\n",
    "        return [X_test.shape[1], 1.0]\n",
    "    else:\n",
    "        X_test_selected = X[:, feature_indices]\n",
    "        knn = KNeighborsClassifier(n_neighbors=5)\n",
    "        knn.fit(X_train1[:, feature_indices], Y_train1)\n",
    "        Y_pred = knn.predict(X_test_selected)\n",
    "        binary_vector = (Y_pred == 1).astype(int)\n",
    "        error_rate = 1 - accuracy_score(Y, Y_pred)\n",
    "        return [len(feature_indices), error_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each solution on the test data\n",
    "Solutions_valid = np.array([evaluate_on_valid_data(X_valid1, Y_valid1, solution) for solution in pop_valid.get(\"X\")])\n",
    "\n",
    "# Perform non-dominated sorting\n",
    "nds = NonDominatedSorting().do(Solutions_valid)\n",
    "\n",
    "# Extract the Pareto front solutions\n",
    "pareto_front_indices = nds[0]\n",
    "pareto_front_objectives = Solutions_valid[pareto_front_indices]\n",
    "\n",
    "# Plot the Pareto front graph\n",
    "print(\"The final Pareto front is plotted as:\")\n",
    "plt.scatter(Solutions_valid[:, 0], Solutions_valid[:, 1], edgecolor=\"blue\", facecolor=\"none\", label=\"Solutions\")\n",
    "plt.scatter(pareto_front_objectives[:, 0], pareto_front_objectives[:, 1], marker='*', edgecolor=\"red\", facecolor=\"none\", label=\"Optimal Pareto front\")\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Test Error')\n",
    "plt.legend()\n",
    "plt.title(\"Visualization of the Final Pareto Front\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pareto_front_objectives[:,0])\n",
    "print(pareto_front_objectives[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84aebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the binary vectors of the Pareto front solutions\n",
    "pareto_front_solutions = pop_valid.get(\"X\")[pareto_front_indices]\n",
    "\n",
    "# Print the Pareto front binary vectors\n",
    "print(\"Binary vectors of the Pareto front solutions:\")\n",
    "for i, solution in enumerate(pareto_front_solutions):\n",
    "    print(f\"Solution {i + 1}: {solution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3c1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
